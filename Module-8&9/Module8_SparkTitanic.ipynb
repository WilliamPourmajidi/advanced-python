{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 – Apache Spark with Titanic Dataset\n",
    "\n",
    "This notebook demonstrates how to use Apache Spark with the Titanic dataset using PySpark. We’ll:\n",
    "- Set up Spark\n",
    "- Load a dataset\n",
    "- Convert it to Spark DataFrame\n",
    "- Perform basic Spark operations\n",
    "- Run SQL queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: PySpark Setup\n",
    "To run this notebook, ensure `pyspark` is installed.\n",
    "- If running locally, install using `pip install pyspark`\n",
    "- In Google Colab, you can use the following:\n",
    "```python\n",
    "!pip install pyspark\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/29 09:44:55 WARN Utils: Your hostname, Williams-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.6.101 instead (on interface en0)\n",
      "25/07/29 09:44:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/29 09:44:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.6.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TitanicSparkDemo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x110649550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"TitanicSparkDemo\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Titanic Dataset\n",
    "We’ll use Seaborn’s version of Titanic dataset for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>male</td>\n",
       "      <td>51.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>female</td>\n",
       "      <td>11.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>female</td>\n",
       "      <td>16.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>female</td>\n",
       "      <td>26.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>male</td>\n",
       "      <td>31.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>female</td>\n",
       "      <td>7.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>29.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>male</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survived  pclass   age     sex     fare\n",
       "0          0       3  22.0    male   7.2500\n",
       "1          1       1  38.0  female  71.2833\n",
       "2          1       3  26.0  female   7.9250\n",
       "3          1       1  35.0  female  53.1000\n",
       "4          0       3  35.0    male   8.0500\n",
       "6          0       1  54.0    male  51.8625\n",
       "7          0       3   2.0    male  21.0750\n",
       "8          1       3  27.0  female  11.1333\n",
       "9          1       2  14.0  female  30.0708\n",
       "10         1       3   4.0  female  16.7000\n",
       "11         1       1  58.0  female  26.5500\n",
       "12         0       3  20.0    male   8.0500\n",
       "13         0       3  39.0    male  31.2750\n",
       "14         0       3  14.0  female   7.8542\n",
       "15         1       2  55.0  female  16.0000\n",
       "16         0       3   2.0    male  29.1250\n",
       "18         0       3  31.0  female  18.0000\n",
       "20         0       2  35.0    male  26.0000\n",
       "21         1       2  34.0    male  13.0000\n",
       "22         1       3  15.0  female   8.0292"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and filter columns\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "df = df[['survived', 'pclass', 'age', 'sex', 'fare']].dropna()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- survived: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      "\n",
      "+--------+------+----+------+-------+\n",
      "|survived|pclass| age|   sex|   fare|\n",
      "+--------+------+----+------+-------+\n",
      "|       0|     3|22.0|  male|   7.25|\n",
      "|       1|     1|38.0|female|71.2833|\n",
      "|       1|     3|26.0|female|  7.925|\n",
      "|       1|     1|35.0|female|   53.1|\n",
      "|       0|     3|35.0|  male|   8.05|\n",
      "|       0|     1|54.0|  male|51.8625|\n",
      "|       0|     3| 2.0|  male| 21.075|\n",
      "|       1|     3|27.0|female|11.1333|\n",
      "|       1|     2|14.0|female|30.0708|\n",
      "|       1|     3| 4.0|female|   16.7|\n",
      "+--------+------+----+------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_spark = spark.createDataFrame(df)\n",
    "df_spark.printSchema()\n",
    "df_spark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Spark DataFrame Operations\n",
    "Basic exploration and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|pclass|          avg(age)|\n",
      "+------+------------------+\n",
      "|     1|38.233440860215055|\n",
      "|     3| 25.14061971830986|\n",
      "|     2| 29.87763005780347|\n",
      "+------+------------------+\n",
      "\n",
      "+------+--------+-----+\n",
      "|pclass|survived|count|\n",
      "+------+--------+-----+\n",
      "|     3|       0|  270|\n",
      "|     1|       0|   64|\n",
      "|     1|       1|  122|\n",
      "|     2|       0|   90|\n",
      "|     2|       1|   83|\n",
      "|     3|       1|   85|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average age of passengers\n",
    "df_spark.groupBy(\"pclass\").avg(\"age\").show()\n",
    "\n",
    "# Count survivors by class\n",
    "df_spark.groupBy(\"pclass\", \"survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed3beb",
   "metadata": {},
   "source": [
    "### Interpreting Spark SQL Queries on Titanic Data\n",
    "\n",
    "In this step, we run **SQL-like queries** on the Spark DataFrame to explore the Titanic dataset:\n",
    "\n",
    "1. **Average Age by Passenger Class**:\n",
    "   - Gives insight into how passenger demographics differed across travel classes.\n",
    "   - Higher-class passengers often had a higher average age.\n",
    "\n",
    "2. **Survival Count by Class**:\n",
    "   - Shows how survival was distributed between classes.\n",
    "   - Useful for understanding social/economic influence on survival probability.\n",
    "\n",
    "3. **Average Fare by Class and Gender**:\n",
    "   - Highlights how ticket cost varied across classes and between male/female passengers.\n",
    "\n",
    "These queries demonstrate how **Spark SQL** allows scalable and intuitive exploration of big data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Spark SQL\n",
    "We can use SQL queries by registering a temporary view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age by Passenger Class:\n",
      "+------+-----------+\n",
      "|Pclass|Average_Age|\n",
      "+------+-----------+\n",
      "|     1|      38.23|\n",
      "|     2|      29.88|\n",
      "|     3|      25.14|\n",
      "+------+-----------+\n",
      "\n",
      "Survival Count by Class:\n",
      "+------+--------+-----+\n",
      "|Pclass|Survived|Count|\n",
      "+------+--------+-----+\n",
      "|     1|       0|   64|\n",
      "|     1|       1|  122|\n",
      "|     2|       0|   90|\n",
      "|     2|       1|   83|\n",
      "|     3|       0|  270|\n",
      "|     3|       1|   85|\n",
      "+------+--------+-----+\n",
      "\n",
      "Average Fare by Class and Gender:\n",
      "+------+------+------------+\n",
      "|Pclass|Sex   |Average_Fare|\n",
      "+------+------+------------+\n",
      "|1     |female|107.95      |\n",
      "|1     |male  |71.14       |\n",
      "|2     |female|21.95       |\n",
      "|2     |male  |21.11       |\n",
      "|3     |female|15.88       |\n",
      "|3     |male  |12.16       |\n",
      "+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.createOrReplaceTempView(\"titanic\")\n",
    "\n",
    "\n",
    "# Query 1: Average age by passenger class\n",
    "avg_age_query = spark.sql(\"\"\"\n",
    "    SELECT Pclass, ROUND(AVG(Age), 2) AS Average_Age\n",
    "    FROM titanic\n",
    "    GROUP BY Pclass\n",
    "    ORDER BY Pclass  \n",
    "\"\"\")\n",
    "print(\"Average Age by Passenger Class:\")\n",
    "avg_age_query.show()\n",
    "\n",
    "\n",
    "# Query 2: Count of survivors by passenger class\n",
    "survival_count_query = spark.sql(\"\"\"\n",
    "    SELECT Pclass, Survived, COUNT(*) AS Count\n",
    "    FROM titanic\n",
    "    GROUP BY Pclass, Survived\n",
    "    ORDER BY Pclass, Survived\n",
    "\"\"\")\n",
    "print(\"Survival Count by Class:\")\n",
    "survival_count_query.show()\n",
    "\n",
    "# # Query 3: Average Fare by class and gender\n",
    "avg_fare_query = spark.sql(\"\"\"\n",
    "    SELECT Pclass, Sex, ROUND(AVG(Fare), 2) AS Average_Fare\n",
    "    FROM titanic\n",
    "    GROUP BY Pclass, Sex\n",
    "    ORDER BY Pclass, Sex\n",
    "\"\"\")\n",
    "print(\"Average Fare by Class and Gender:\")\n",
    "avg_fare_query.show(truncate=False)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
